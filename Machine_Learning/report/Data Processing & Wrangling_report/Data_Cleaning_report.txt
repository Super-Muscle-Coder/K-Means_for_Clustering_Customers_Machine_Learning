====================================================================================================
THỰC HIỆN QUY TRÌNH LÀM SẠCH DỮ LIỆU HOÀN CHỈNH
====================================================================================================
Bước 1: TẢI VÀ ĐỌC DỮ LIỆU

Dữ liệu đã được tải thành công

[13:45:16] Tải dữ liệu thành công


====================================================================================================
Bước 1: TÁCH DATASET THEO MISSING VALUES
====================================================================================================
[13:45:16] Tách dataset theo missing values
    └─ Tách 24 dòng có missing thành mini dataset


====================================================================================================
Bước 2: LOẠI BỎ DÒNG TRÙNG LẶP FEATURE
====================================================================================================
[13:45:17] Loại bỏ dòng trùng lặp feature
    └─ Đã loại bỏ 182 dòng, còn lại 2034 dòng


====================================================================================================
Bước 3: LOẠI BỎ OUTLIERS CỤ THỂ
====================================================================================================
[13:45:28] Loại bỏ outliers cụ thể
    └─ Đã loại bỏ 3 dòng (Income: 1, Year_Birth: 2)


====================================================================================================
Bước 4: CHUẨN HÓA MARITAL_STATUS
====================================================================================================
[13:45:28] Chuẩn hóa Marital_Status
    └─ Đã thay đổi 7 giá trị


====================================================================================================
Bước 5: CHUYỂN ĐỔI KIỂU DỮ LIỆU
====================================================================================================
[13:45:28] Chuyển đổi kiểu dữ liệu
    └─ Dt_Customer: object → datetime64[ns]

[13:45:28] Bắt đầu encode Education
    └─ Cột: Education → Education_ord, Mapping: ['Basic', '2n Cycle', 'Graduation', 'Master', 'PhD']


====================================================================================================
Bước 6: ENCODE EDUCATION THÀNH CÔNG
====================================================================================================
[13:45:28] Encode Education thành công
    └─ Tất cả giá trị đã được mapping

[13:45:28] Hoàn thành encode Education
    └─ Cột mới: Education_ord, Unmapped: 0


====================================================================================================
Bước 7: ENCODE MARITAL_STATUS (ONE-HOT)
====================================================================================================
[13:45:28] Encode Marital_Status (one-hot)
    └─ Rare grouped: 1, Dummies: 6

[13:45:28] Ensure binary dtypes
    └─ Casted 6 columns to uint8: ['Marital_Divorced', 'Marital_Married', 'Marital_Other', 'Marital_Single', 'Marital_Together', 'Marital_Widow']


====================================================================================================
Bước 8: LOẠI BỎ FULL-ROW DUPLICATES SAU DROP ID
====================================================================================================
[13:45:28] Loại bỏ full-row duplicates sau drop ID
    └─ Đã loại bỏ 21 dòng


====================================================================================================
Bước 9: LOẠI BỎ FEATURES KHÔNG PHỤC VỤ NHÂN KHẨU HỌC
====================================================================================================
[13:45:28] Loại bỏ features không phục vụ nhân khẩu học
    └─ Đã loại bỏ 10 cột và lưu vào archived dataset


====================================================================================================
Bước 10: XÁC THỰC DỮ LIỆU
====================================================================================================
[13:45:28] Xác thực dữ liệu
    └─ Tất cả kiểm tra đều thành công

[13:45:28] Xuất dữ liệu
    └─ Đã xuất ra file C:\Project\Machine_Learning\Machine_Learning\Dataset\Customer_Behavior_cleaned.csv

